# Image-to-Text com CNN e GPT-2

Este projeto foi desenvolvido como trabalho final da disciplina de **Aprendizado Profundo** da UFMG e tem como objetivo implementar um sistema de **Image-to-Text** â€” geraÃ§Ã£o automÃ¡tica de legendas para imagens â€” integrando visÃ£o computacional e processamento de linguagem natural.

## ğŸ“Œ Objetivo

Gerar descriÃ§Ãµes textuais coerentes e contextualmente relevantes a partir de imagens, explorando a conexÃ£o entre visÃ£o e linguagem, com aplicaÃ§Ãµes em acessibilidade, indexaÃ§Ã£o de imagens e sistemas inteligentes.

## ğŸ” RelevÃ¢ncia

- **ConexÃ£o entre visÃ£o e linguagem**: integra modelos visuais e de linguagem natural.
- **Acessibilidade**: auxilia usuÃ¡rios com deficiÃªncia visual.
- **Busca e organizaÃ§Ã£o**: melhora indexaÃ§Ã£o e recuperaÃ§Ã£o de imagens.
- **Base para aplicaÃ§Ãµes avanÃ§adas**: Ãºtil para assistentes virtuais e robÃ³tica.

## ğŸ§  Abordagem

O modelo Ã© composto por:

- **Encoder**: CNN customizada, implementada do zero, para extrair embeddings visuais.
- **Decoder**: **GPT-2** prÃ©-treinado, adaptado para receber embeddings de imagens como prefixo de entrada.
- **Treinamento**: fine-tuning seletivo no GPT-2, mantendo congeladas as camadas iniciais.

## ğŸ“Š Dataset

- **Base**: [DeepFashion](http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html)
- **Subconjunto**: 3.000 imagens de peÃ§as de roupa, cada uma com descriÃ§Ã£o curta.
- **PrÃ©-processamento**:
  - Redimensionamento para 224x224 pixels
  - NormalizaÃ§Ã£o com mÃ©dias e desvios do ImageNet
  - TokenizaÃ§Ã£o com `GPT2Tokenizer`
- **Data Augmentation**:
  - Flip horizontal
  - Crop aleatÃ³rio e resize
  - Jitter de brilho e contraste

## âš™ï¸ Arquitetura

### Encoder (CNN)

- 4 blocos convolucionais com:
  - Conv2d â†’ BatchNorm â†’ ReLU â†’ MaxPool
- AdaptiveAvgPool e camada Linear para projeÃ§Ã£o final.

### Decoder (GPT-2)

- ProjeÃ§Ã£o do embedding visual para o espaÃ§o de embeddings do GPT-2.
- ConcatenaÃ§Ã£o com embeddings de tokens textuais.
- MÃ¡scara de atenÃ§Ã£o adaptada.
- Fine-tuning nas Ãºltimas 4 camadas e na `lm_head`.

### Modelo Final

```text
Imagem â†’ Encoder (CNN) â†’ Embedding visual â†’ Decoder (GPT-2) â†’ Legenda
```
